{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ca17fe-88ea-4b0e-8844-0b3552ce32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3c1140-b268-4d30-9e8e-c3d17a95125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(params_path, angles_path, energies_path, names_params, drop_nan = False):\n",
    "    params = np.load(params_path)\n",
    "    angles = np.load(angles_path, allow_pickle = True)\n",
    "    energies = np.load(energies_path, allow_pickle = True)\n",
    "    \n",
    "    data = {}\n",
    "    for k in range(params.shape[0]):\n",
    "        data[names[k]] = params[:,k]\n",
    "    \n",
    "    data['Tf'] = angles[:,0]\n",
    "    data['Pf'] = angles[:,1]\n",
    "    data['Ef/Ei'] = energies\n",
    "    \n",
    "    if(drop_nan):\n",
    "        df = pd.DataFrame(data)\n",
    "        return df.dropna(subset = [\"Tf\"], inplace=True) # for example 'Tf'\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f38211e-1a89-4899-b6f6-cdb6133566bb",
   "metadata": {},
   "source": [
    "## Loading the dataframe with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c800a-8a82-4715-8eb5-1e0a25fbda56",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_path = ''\n",
    "angles_path = ''\n",
    "energies_path = ''\n",
    "names_params = ['Ei','Ti','Pi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769de8f6-2a1a-4b79-9dc8-bc39fa12cde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(params_path, angles_path, energies_path, names_params, drop_nan = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ebda9-51fc-495c-bae5-07309bd39903",
   "metadata": {},
   "source": [
    "## Simple plottingfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d858ccf6-ad37-46b1-9177-17b534ef0899",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2)\n",
    "ax[0,0].plot(df['Ti'],df['Ef/Ei'],'.')\n",
    "ax[0,1].plot(df['Ti'],df['Tf'],'.')\n",
    "ax[1,0].plot(df['Pi'],df['Ef/Ei'],'.')\n",
    "ax[1,1].plot(df['Ei'],df['Ef/Ei'],'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641842b4-7aec-4628-9320-2d6645bd3fa4",
   "metadata": {},
   "source": [
    "## Sensibility analysis\n",
    "Using [SALib](https://salib.readthedocs.io/en/latest/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d9f681-2b41-4124-ac29-0f6ee703e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol\n",
    "from SALib.test_functions import Ishigami\n",
    "from .modules.plotting import plot_sobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae73b9-7fbb-402a-8e41-4260d409e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = {\n",
    "    'num_vars': 2,\n",
    "    'names': ['Ei', 'Ti'],\n",
    "    'bounds': [[1.0, 150], # eV\n",
    "                [-90, 90]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cebbdbc-0389-442e-824b-8c4ca4003ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_values = df[names_params].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81ccd5b-dbf7-49d4-b79e-940555ae1981",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.zeros((param_values.shape[0],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1e21fd-0ff8-4a92-b256-a347fb9e3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[:,0] = df['Ef/Ei']\n",
    "Y[:,1] = df['Tf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e316a17-e12d-488f-8fc5-e855fa07b697",
   "metadata": {},
   "outputs": [],
   "source": [
    "Si_energy = sobol.analyze(problem, Y[:,0])\n",
    "Si_polar_angle = sobol.analyze(problem, Y[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf066cbb-d4eb-43c3-abd9-c3d1660748f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sobol(Si_energy['S1'],Si_energy['ST'], title = 'Sobol Analysis - Out energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed672529-dcc3-48bf-8a8e-e33252afee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sobol(Si_polar_angle['S1'],Si_polar_angle['ST'], title = 'Sobol Analysis - Out polar angle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e649c5-2972-4ebd-8f84-04069aac2ba7",
   "metadata": {},
   "source": [
    "# Machine Learning - trial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3306e57-ea1c-4d78-9bff-85f1eb89b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation des données \n",
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e8fde7-b03a-4314-b60b-69cfa44177c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting \n",
    "def preprocessed(data, start_idx_ground_truth, splitting = 0.6):\n",
    "    s = data.shape\n",
    "    np.random.shuffle(data)\n",
    "    splittinglimit = int(splitting*s[0])\n",
    "    \n",
    "    training_set = data[:splittinglimit]\n",
    "    testing_set = data[splittinglimit:]\n",
    "        \n",
    "        # converting to torch tensors\n",
    "    x_train = torch.Tensor(training_set[:,:start_idx_ground_truth])\n",
    "    y_train = torch.Tensor(training_set[:,start_idx_ground_truth:])\n",
    "    x_test = torch.Tensor(testing_set[:,:start_idx_ground_truth])\n",
    "    y_test = torch.Tensor(testing_set[:,start_idx_ground_truth:])\n",
    "    \n",
    "        # normalizing\n",
    "    # x_test = nn.functional.normalize(x_test, p=2, dim=0)\n",
    "    # x_train = nn.functional.normalize(x_train, p=2, dim=0)\n",
    "    \n",
    "        # creating datasetabs    \n",
    "    training_dataset = torch.utils.data.TensorDataset(x_train,y_train)\n",
    "    testing_dataset = torch.utils.data.TensorDataset(x_test,y_test)\n",
    "    \n",
    "    return (training_dataset, testing_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f149fbf4-0249-4b41-84d1-ff79245f82e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset, testing_dataset = preprocessed(df[['Ei','Ti','Ef/Ei','Tf']].values, start_idx_ground_truth = 2, splitting = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e63dc5d-83b0-4ff6-9ddd-d62a6f048e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of a testloader\n",
    "#testloader = torch.utils.data.DataLoader(test_data, len(test_data), shuffle=True)\n",
    "\n",
    "def train_epoch(net, opt, criterion, trainloader, batch_size=50): # pour entraîner sur un epoch\n",
    "    net.train()\n",
    "    losses = []\n",
    "    for x_batch, y_batch in trainloader:\n",
    "        opt.zero_grad()\n",
    "        # Forward\n",
    "        y_comp = net(x_batch)\n",
    "        # Compute diff\n",
    "        loss = criterion(y_comp, y_batch)\n",
    "        # Compute gradients\n",
    "        loss.sum().backward()\n",
    "        # update weights\n",
    "        opt.step()\n",
    "        losses.append(loss.data.numpy())\n",
    "    return losses\n",
    "\n",
    "def accuracy(net, dataset): # pour calculer la précision\n",
    "    net.eval() # pass the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sqe = 0\n",
    "    count = 0\n",
    "    for data in dataset:\n",
    "        points, ground_truth = data\n",
    "        outputs = net(points)\n",
    "        #print(outputs, labels)\n",
    "        if(np.isnan(ground_truth.detach().numpy()).any()):\n",
    "            count += 1\n",
    "        else:\n",
    "            sum_err = (outputs-ground_truth)**2 # problem : we have nan at this point\n",
    "            sqe += np.mean(sum_err.detach().numpy())\n",
    "    net.train() # pass the model to training mode\n",
    "    #print(count)\n",
    "    return sqe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bb2545-17b6-4f9d-a044-3937b139430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, deepness = 10, weights_nb = 256):\n",
    "        super(Net, self).__init__()\n",
    "        self.inputlayer = nn.Linear(2,weights_nb)\n",
    "        liste = []\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        for k in range(deepness):\n",
    "            liste.append(nn.Linear(weights_nb,weights_nb))\n",
    "            liste.append(self.relu)\n",
    "        self.hiddenlayers = nn.Sequential(*liste)\n",
    "        self.outputlayer = nn.Linear(weights_nb,2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # intput layer\n",
    "        x = self.inputlayer(x)\n",
    "        x = self.relu(x)\n",
    "        # hidden layers\n",
    "        x = self.hiddenlayers(x)\n",
    "        # output layer\n",
    "        x = self.outputlayer(x)\n",
    "       #x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496ce23e-a2f3-4a4a-ad87-0936f32843cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(train_data, test_data, model, batch_size = 64, epochs = 10, lr = 1e-4):\n",
    "    \"\"\"\n",
    "    this function returns a list of precision - 1 precision / epoch - for the given training and testing data, for the given model\n",
    "    \"\"\"\n",
    "    testloader = torch.utils.data.DataLoader(test_data, 1, shuffle=False)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True)\n",
    "    net = model\n",
    "    \n",
    "    # criterion for the last and optimizer\n",
    "    def criterion(x,y):\n",
    "        n = len(x)\n",
    "        s = 0\n",
    "        for k in range(n):\n",
    "            s+=(x[k]-y[k])*(x[k]-y[k]) # mean square error\n",
    "        return s/n\n",
    "    \n",
    "    opt = torch.optim.Adam(net.parameters(),lr,betas=(0.9, 0.999),eps=1e-08)\n",
    "    accuracy_list = []\n",
    "    #accuracy_list_train = []\n",
    "    for k in tqdm.tqdm(range(epochs)):\n",
    "        net.train()\n",
    "        train_epoch(net, opt, criterion, trainloader, batch_size = batch_size)\n",
    "        prec=accuracy(net, dataset = testloader)\n",
    "        if(k%10==0):\n",
    "            print(f'{k} : accuracy = {prec}')\n",
    "        accuracy_list.append(prec)\n",
    "        #accuracy_list_train.append(accuracy(net, dataset = trainloader))\n",
    "    return (net , accuracy_list) # this way we can keep the trained net and test it some more after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119a2dec-b29d-472f-bb58-98998570f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(deepness = 2, weights_nb = 16)\n",
    "net, accuracy_list = test_model(training_dataset, testing_dataset, net, batch_size = 1, epochs = 100, lr=1e-2) # 1e-2 ~ 1% of the total value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000bdd3b-b242-4844-ab81-e0beac5e22b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(doe, 1, shuffle=False)\n",
    "print(accuracy(net, testing_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85190802-076d-4a79-bb61-1c17ffcd9d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doe_valid = np.load('doe_valid.npy')\n",
    "angles_valid = np.load('angles_valid.npy', allow_pickle = True)\n",
    "energies_valid = np.load('ratio_energies_valid.npy', allow_pickle = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
